{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推荐系统算法\n",
    "\n",
    "这里简单介绍下推荐系统中最为主要的**协同过滤算法**，大致分为如下几类：\n",
    "\n",
    "* 基于用户的协同过滤（给用户推荐与他相似的人购买的物品）\n",
    "* 基于商品的协同过滤（给用户推荐和他之前喜欢的物品相似的物品）\n",
    "* 基于模型的协同过滤：关联算法，聚类算法，分类算法，回归算法，矩阵分解，神经网络,图模型以及隐语义模型都属于这个范畴。\n",
    "\n",
    "而本次实战使用的是矩阵分解算法。\n",
    "\n",
    "矩阵分解其实是数学上的一个经典问题。大家从线性代数中可以知道，\n",
    "**矩阵可以做SVD分解、Cholesky分解等，就好比任何大于1的正整数都可以分解成若干质数的乘积，矩阵分解可以认为是一种信息压缩。**\n",
    "\n",
    "下图是一个用户电影评分矩阵。矩阵的每行表示一个用户，每列表示一部电影，矩阵中每个位置的值，代表某个用户对某个电影的评分值。\n",
    "\n",
    "![img](img/1.png)\n",
    "\n",
    "* R矩阵:用户对电影的评分组合矩阵，\n",
    "* 用户矩阵，每一个被压缩的行向量代表一个用户的信息向量，\n",
    "* 电影矩阵，每一个被压缩列向量代表一个电影的信息向量。\n",
    "\n",
    "而这样的矩阵分解压缩过程，使得用户矩阵和电影矩阵都具有了一定的语义信息，必须强调的是**用户矩阵行向量的维数和电影矩阵列向量维数是相等的**。所以本质上就是将每个用户和每个电影通过已有的打分信息Embedding到同一维度的信息向量空间。\n",
    "\n",
    "**接下来我们就学习一下如何使用keras对R矩阵进行矩阵分解，获得每个电影和每个用户的信息向量。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoyadong/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rating = pd.read_csv(\"data/ratings.dat\",sep=\"::\",header=None)\n",
    "rating.columns = ['userId','movieId','rating','timestamp']\n",
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3952 1000209\n"
     ]
    }
   ],
   "source": [
    "num_user = np.max(rating[\"userId\"])\n",
    "num_movie = np.max(rating[\"movieId\"])\n",
    "print(num_user,num_movie,len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中num_user = 6040, num_movie = 3952 len(rating)=1000209。\n",
    "\n",
    "意味着我的数据中有6040为观众，3952 部电影，得到了1000209个评分数据。\n",
    "\n",
    "从这些我们可以计算出上图用户电影组合的R矩阵的填充率。\n",
    "\n",
    "1000209/(6040*3952) = 0.04190220560634904\n",
    "\n",
    "这说明只有4.2%的用户电影组合有评分，当然这和实际情况是相符的，毕竟一个人只会给很少部分的电影评分，所以我们发现用户对电影的评分组合矩阵R极其稀疏。\n",
    "\n",
    "所以接下来我们要做的就是**预测那些没有评分的用户电影组合可能的得分，填充R矩阵，这样就可以为用户推荐模型预测得分较高的电影。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dot\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "def Recmand_model(num_user,num_movie,k):\n",
    "    input_uer = Input(shape=[None,],dtype=\"int32\")\n",
    "    model_uer = Embedding(num_user+1,k,input_length = 1)(input_uer)\n",
    "    model_uer = Reshape((k,))(model_uer)\n",
    "    \n",
    "    input_movie = Input(shape=[None,],dtype=\"int32\")\n",
    "    model_movie  = Embedding(num_movie+1,k,input_length = 1)(input_movie)\n",
    "    model_movie = Reshape((k,))(model_movie)\n",
    "    \n",
    "    out = Dot(1)([model_uer,model_movie])\n",
    "    model = Model(inputs=[input_uer,input_movie], outputs=out)\n",
    "    model.compile(loss='mse', optimizer='Adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里就是**矩阵分解的部分**，模型的架构图如下图所示：\n",
    "\n",
    "将用户和电影通过**Eembdding层压缩到k维度向量，**\n",
    "\n",
    "然后简单粗暴直接向量点乘，\n",
    "\n",
    "得到用户对电影的预测评分。\n",
    "\n",
    "这里误差采用平方误差MSE，优化器采用的是Adam。\n",
    "\n",
    "> 1.对于loss函数来说，是否应该加入正则项和用户&物品的偏置，评分系统的平均分？\n",
    "\n",
    "> 2.这样寻找用户和物品的embedding的话是不是就是在做SVD分解？还是说利用深度学习的方法来让它自己找出来他们分解后的矩阵呢？\n",
    "\n",
    "> 1.loss函数中的正则项我没有加，加了从原理上来说应该更好。\n",
    "\n",
    "> 2.对的就是做类似于SVD的矩阵分解，只不过利用深度学习的方式找分解后分矩阵。\n",
    "\n",
    "![img](img/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    604100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    395300      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100)          0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 100)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 999,400\n",
      "Trainable params: 999,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Recmand_model(num_user,num_movie,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n",
    "\n",
    "将数据准备成( [用户ID, 电影ID] , 用户ID对电影ID的评分 ）这种格式。接下来就可以把数据喂给模型了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = rating[\"userId\"].values\n",
    "train_movie = rating[\"movieId\"].values\n",
    "\n",
    "train_x = [train_user,train_movie]\n",
    "train_y = rating[\"rating\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿到输入数据之后，设置好batch_size,epoch，就可以进行训练了。运行下面代码让模型跑起来。\n",
    "\n",
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000209 samples\n",
      "Epoch 1/10\n",
      "1000209/1000209 [==============================] - 36s 35us/sample - loss: 2.5846\n",
      "Epoch 2/10\n",
      "1000209/1000209 [==============================] - 36s 36us/sample - loss: 0.8020\n",
      "Epoch 3/10\n",
      "1000209/1000209 [==============================] - 38s 38us/sample - loss: 0.6974\n",
      "Epoch 4/10\n",
      "1000209/1000209 [==============================] - 40s 40us/sample - loss: 0.5919\n",
      "Epoch 5/10\n",
      "1000209/1000209 [==============================] - 38s 38us/sample - loss: 0.4942\n",
      "Epoch 6/10\n",
      "1000209/1000209 [==============================] - 38s 38us/sample - loss: 0.4199\n",
      "Epoch 7/10\n",
      "1000209/1000209 [==============================] - 39s 39us/sample - loss: 0.3704\n",
      "Epoch 8/10\n",
      "1000209/1000209 [==============================] - 39s 39us/sample - loss: 0.3369\n",
      "Epoch 9/10\n",
      "1000209/1000209 [==============================] - 39s 39us/sample - loss: 0.3137\n",
      "Epoch 10/10\n",
      "1000209/1000209 [==============================] - 38s 38us/sample - loss: 0.2972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11f4e8e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,batch_size = 100,epochs =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "十个epoch之后loss只有0.2972，这样我们就可以不严谨的下结论：模型的预测误差不超出0.1，接下来是预测部分。\n",
    "\n",
    "# 模型预测\n",
    "\n",
    "从之前读入数据中可以得知，**userId为1的用户，没有对movieId为2的电影评分。**\n",
    "\n",
    "我们就用模型试试userId为1的用户会为movieId为2的电影打多少数分呢？运行下方代码，便能知晓。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>978301777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "      <td>978824195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating  timestamp\n",
       "40       1        1       5  978824268\n",
       "25       1       48       5  978824351\n",
       "39       1      150       5  978301777\n",
       "44       1      260       4  978300760\n",
       "23       1      527       5  978824195"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.sort_values(['userId','movieId'],ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.417516]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[1],[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出结果：**array([[2.417516]], dtype=float32)**\n",
    "\n",
    "模型预测为2.4，而评分的总分为5分，意味着userId为1的用户很有可能会喜欢movieId为2的电影。\n",
    "\n",
    "可以考虑将movieId为2的电影推荐给userId为1的用户。\n",
    "\n",
    "# 总结\n",
    "\n",
    "这里只是采用了最简单的方式做了一个简单的推荐系统，而且此方式很难解决新的电影和新的用户的推荐问题。推荐系统是门很深的学问，算法不仅需要考虑到推荐的准确率，覆盖率，还要考虑到推荐内容的丰富性和新颖性。人是很容易改变和厌倦的动物，所以，笔者有时候在想真会出现一个一直都懂你的推荐算法吗？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
