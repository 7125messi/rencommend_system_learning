阿里近几年公开的推荐领域算法可真不少，既有传统领域的探索如MLR算法，还有深度学习领域的探索如entire -space multi-task model，Deep Interest Network等，同时跟清华大学合作展开了强化学习领域的探索，提出了MARDPG算法。

从本篇开始，我们就一起来探秘这些算法。这里，我们只是大体了解一下每一个算法的思路，对于数学部分的介绍，我们不会过多的涉及。

# 1、算法介绍

现阶段各CTR预估算法的不足

| 方法 | 简介 | 不足 |
| --- | :---: | :---: |
| 逻辑回归 | 使用了Sigmoid函数将函数值映射到0~1区间作为CTR的预估值。LR这种线性模型很容易并行化，处理上亿条训练样本不是问题。 | 线性模型的学习能力有限，需要引入大量的领域知识来人工设计特征以及特征之间的交叉组合来间接补充算法的非线性学习能力，非常消耗人力和机器资源，迁移性不够友好。 |
| Kernel方法 | 将低维特征映射到高维特征空间 | 复杂度太高而不易实现 |
| 树模型 | 如Facebook的GBDT+LR算法，有效地解决了LR模型的特征组合问题 | 是对历史行为的记忆，缺乏推广性，树模型只能学习到历史数据中的特定规则，对于新规则缺乏推广性 |
| FM模型 | 自动学习高阶属性的权值，不用通过人工的方式选取特征来做交叉 | FM模型只能拟合特定的非线性模式，常用的就是二阶FM |
| 深度神经网络 | 使用神经网络拟合数据之间的高阶非线性关系，非线性拟合能力足够强 | 适合数据规律的、具备推广性的网络结构业界依然在探索中，尤其是要做到端到端规模化上线，这里面的技术挑战依然很大 |

**那么挑战来了，如何设计算法从大规模数据中挖掘出具有推广性的非线性模式？**

# 2、MLR算法

2011-2012年期间，阿里妈妈资深专家盖坤创新性地提出了**MLR(mixed logistic regression)算法，引领了广告领域CTR预估算法的全新升级**。**MLR算法创新地提出并实现了直接在原始空间学习特征之间的非线性关系，基于数据自动发掘可推广的模式，相比于人工来说效率和精度均有了大幅提升。**

论文：https://arxiv.org/pdf/1704.05194.pdf

**MLR可以看做是对LR的一个自然推广，它采用分而治之的思路，用分片线性的模式来拟合高维空间的非线性分类面**，其形式化表达如下：

$$
p(y=1 | x)=g\left(\sum_{j=1}^{m} \sigma\left(u_{j}^{T} x\right) \eta\left(w_{j}^{T} x\right)\right)
$$

其中u是聚类参数，决定了空间的划分，w是分类参数，决定空间内的预测。这里面超参数分片数m可以较好地平衡模型的拟合与推广能力。当m=1时MLR就退化为普通的LR，m越大模型的拟合能力越强，但是模型参数规模随m线性增长，相应所需的训练样本也随之增长。因此实际应用中m需要根据实际情况进行选择。例如，在阿里的场景中，m一般选择为12。下图中MLR模型用4个分片可以完美地拟合出数据中的菱形分类面。

![img](img/1.png)

在实际中，MLR算法常用的形式如下，使用softmax作为分片函数：

$$
p(y=1 | x)=\sum_{i=1}^{m} \frac{\exp \left(u_{i}^{T} x\right)}{\sum_{j=1}^{m} \exp \left(u_{j}^{T} x\right)} \cdot \frac{1}{1+\exp \left(-w_{i}^{T} x\right)}
$$

在这种情况下，MLR模型可以看作是一个FOE model：

$$
p(y=1 | x)=\sum_{i=1}^{m} p(z=i | x) p(y | z=i, x)
$$

关于损失函数的设计，阿里采用了 neg-likelihood loss function以及L1，L2正则，形式如下：

$$
\begin{array}{c}{\arg \min _{\Theta} f(\Theta)=\operatorname{loss}(\Theta)+\lambda\|\Theta\|_{2,1}+\beta\|\Theta\|_{1}} \\ {\operatorname{loss}(\Theta)=-\sum_{t=1}^{n}\left[y_{t} \log \left(p\left(y_{t}=1 | x_{t}, \Theta\right)\right)+\left(1-y_{t}\right) \log \left(p\left(y_{t}=0 | x_{t}, \Theta\right)\right)\right]}\end{array}
$$

由于加入了正则项，MLR算法变的不再是平滑的凸函数，梯度下降法不再适用，因此模型参数的更新使用LBFGS和OWLQN的结合。

MLR算法适合于工业级的大规模稀疏数据场景问题，如广告CTR预估。背后的优势体现在两个方面：
- **端到端的非线性学习**：**从模型端自动挖掘数据中蕴藏的非线性模式，省去了大量的人工特征设计，这 使得MLR算法可以端到端地完成训练，在不同场景中的迁移和应用非常轻松。**
- **稀疏性**：MLR在建模时引入了L1和L2,1范数正则，可以使得最终训练出来的模型具有较高的稀疏度， 模型的学习和在线预测性能更好。当然，这也对算法的优化求解带来了巨大的挑战。