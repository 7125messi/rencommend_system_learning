{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用keras搭建一个基于矩阵分解的推荐系统,而那篇文章所介绍的方法可能只是一个庞大推荐系统中的一小环节。而对于工业级别的推荐系统，面对极其庞大的产品种类数量，一步就输出符合用户心意的产品可能够呛，最好的方式应该是从巨大的产品类别之中粗筛出一些靠谱的待推荐产品，然后再从粗筛的产品中精挑细选出要推荐给用户的最终产品。\n",
    "\n",
    "# 1 工业级别的推荐系统简介\n",
    "\n",
    "工业级别的推荐系统的架构图如下图所示，大致分为两个阶段：\n",
    "\n",
    "* **召回阶段**：也就是**粗筛阶段**，由于涉及到的产品数量巨大，大的公司都是千万级别，甚至上亿级别的产品数量，**此阶段的模型应该尽量简单，特征维度也尽量少，这样方便快速筛选出一些待推荐的产品。**\n",
    "\n",
    "* **排序阶段**：即对上一阶段粗筛出来的待推荐产品进行**精挑细选**，此阶段**为了推荐出符合用户心意的产品，需要模型尽量的准确**。而且由于**粗筛阶段将数据量减少到几千，甚至几百级别，所以使用复杂模型，并且特征维度也可以尽量丰富，尽量多一些，这样训练出来的模型才能有较强的性能**。\n",
    "\n",
    "![img](img/1.png)\n",
    "\n",
    "而接下来我要介绍的FM（Factorization Machine）算法，不仅在召回阶段有用武之地，在排序阶段也是很拿得出手的推荐模型。\n",
    "\n",
    "# 2 FM（Factorization Machine）算法简介\n",
    "\n",
    "Factorization Machine的中文叫因子分解机，FM算法的最强特点就是**考虑到了特征的二阶组合——即特征两两组合形成一个新的特征。**\n",
    "\n",
    "**在产品推荐，CTR预估等任务中，特征相互组合很可能会得到一个特别强的新特征。接下来我们从FM算法的公式来了解一下此算法的精髓：**\n",
    "\n",
    "$$\n",
    "y=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i}+\\sum_{i=1}^{n} \\sum_{i=j+1}^{n}<v_{i}, v_{j}>x_{i} x_{j}\n",
    "$$\n",
    "\n",
    "如果我们单看FM算法的前面一部分：\n",
    "\n",
    "$$\n",
    "y=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i}\n",
    "$$\n",
    "\n",
    "这不就是一个Logistics回归模型吗，确实没错，FM算法的前半部分就是Logistics回归，算法的后半部分才体现出FM的特征组合的思想：\n",
    "\n",
    "![img](img/2.png)\n",
    "\n",
    "$$\n",
    "y=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i}+0.5 \\sum_{i=1}^{k} \\sum_{i=1}^{n}\\left(\\left(v_{i, f} x_{i}\\right)^{2}-\\sum_{i=1}^{n} v_{i, f}^{2} x_{i}^{2}\\right)\n",
    "$$\n",
    "\n",
    "不要小看了公式的改写这一步，公式的改写这一过程会带来了算法时间复杂度的下降，加速算法的运行。接下来我们就尝试使用keras实现一下FM算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 FM算法实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FM层的定义，其中call函数中定义了FM的主要实现部分\n",
    "\n",
    "class FM(Layer):\n",
    "    def __init__(self, output_dim=30, activation=\"relu\",**kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.activate = activations.get(activation)\n",
    "        super(FM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.wight = self.add_weight(name='wight', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='bias', \n",
    "                                      shape=(self.output_dim,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        super(FM, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        feature =  K.dot(x,self.wight) + self.bias\n",
    "        a = K.pow(K.dot(x,self.kernel), 2)\n",
    "        b = K.dot(x, K.pow(self.kernel, 2))\n",
    "        cross = K.mean(a-b, 1, keepdims=True)*0.5\n",
    "        cross = K.repeat_elements(K.reshape(cross, (-1, 1)), self.output_dim, axis=-1)\n",
    "        return self.activate(feature + cross)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据载入\n",
    "载入sklearn中乳腺癌的分类任务数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()[\"data\"]\n",
    "target = load_breast_cancer()[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建\n",
    "这里我采用了一层FM层，一层15个神经元的隐层构建了一个两层的网络模型，Loss 采用的是平方误差损失（mse），当然也可以采用交叉熵损失（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 481\n",
      "Trainable params: 481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(30,))\n",
    "out = FM(20)(inputs)\n",
    "out = Dense(15,activation=\"sigmoid\")(inputs)\n",
    "out = Dense(1,activation=\"sigmoid\")(out)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss='mse',\n",
    "              optimizer=Adam(0.0001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "定义好batch_size 和训练轮数，就可以将模型跑起来了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 0.2441 - accuracy: 0.5912 - val_loss: 0.1956 - val_accuracy: 0.7719\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 738us/sample - loss: 0.2427 - accuracy: 0.5912 - val_loss: 0.1921 - val_accuracy: 0.7719\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 759us/sample - loss: 0.2343 - accuracy: 0.5912 - val_loss: 0.1848 - val_accuracy: 0.7719\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 786us/sample - loss: 0.2301 - accuracy: 0.5912 - val_loss: 0.1846 - val_accuracy: 0.7719\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 808us/sample - loss: 0.2277 - accuracy: 0.5912 - val_loss: 0.1838 - val_accuracy: 0.7719\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 769us/sample - loss: 0.2252 - accuracy: 0.5912 - val_loss: 0.1837 - val_accuracy: 0.7719\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 776us/sample - loss: 0.2234 - accuracy: 0.5912 - val_loss: 0.1834 - val_accuracy: 0.7719\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 790us/sample - loss: 0.2211 - accuracy: 0.5912 - val_loss: 0.1828 - val_accuracy: 0.7719\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 761us/sample - loss: 0.2189 - accuracy: 0.5912 - val_loss: 0.1822 - val_accuracy: 0.7719\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 742us/sample - loss: 0.2171 - accuracy: 0.5912 - val_loss: 0.1819 - val_accuracy: 0.7719\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 744us/sample - loss: 0.2149 - accuracy: 0.5912 - val_loss: 0.1813 - val_accuracy: 0.7719\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 745us/sample - loss: 0.2131 - accuracy: 0.5912 - val_loss: 0.1804 - val_accuracy: 0.7719\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 750us/sample - loss: 0.2114 - accuracy: 0.5912 - val_loss: 0.1795 - val_accuracy: 0.7719\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 760us/sample - loss: 0.2095 - accuracy: 0.5912 - val_loss: 0.1788 - val_accuracy: 0.7719\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 810us/sample - loss: 0.2076 - accuracy: 0.5912 - val_loss: 0.1779 - val_accuracy: 0.7719\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 799us/sample - loss: 0.2061 - accuracy: 0.5912 - val_loss: 0.1775 - val_accuracy: 0.7719\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 827us/sample - loss: 0.2042 - accuracy: 0.5912 - val_loss: 0.1761 - val_accuracy: 0.7719\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 852us/sample - loss: 0.2026 - accuracy: 0.5912 - val_loss: 0.1752 - val_accuracy: 0.7719\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 828us/sample - loss: 0.2006 - accuracy: 0.5912 - val_loss: 0.1756 - val_accuracy: 0.7719\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 734us/sample - loss: 0.1992 - accuracy: 0.5912 - val_loss: 0.1731 - val_accuracy: 0.7719\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 742us/sample - loss: 0.1979 - accuracy: 0.5912 - val_loss: 0.1727 - val_accuracy: 0.7719\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 745us/sample - loss: 0.1957 - accuracy: 0.5912 - val_loss: 0.1710 - val_accuracy: 0.7719\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 706us/sample - loss: 0.1939 - accuracy: 0.5912 - val_loss: 0.1699 - val_accuracy: 0.7719\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 708us/sample - loss: 0.1920 - accuracy: 0.5912 - val_loss: 0.1701 - val_accuracy: 0.7719\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 728us/sample - loss: 0.1908 - accuracy: 0.8264 - val_loss: 0.1682 - val_accuracy: 0.8772\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 741us/sample - loss: 0.1892 - accuracy: 0.8923 - val_loss: 0.1670 - val_accuracy: 0.8772\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 740us/sample - loss: 0.1874 - accuracy: 0.8857 - val_loss: 0.1667 - val_accuracy: 0.8860\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 698us/sample - loss: 0.1861 - accuracy: 0.8879 - val_loss: 0.1650 - val_accuracy: 0.8772\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 704us/sample - loss: 0.1847 - accuracy: 0.8879 - val_loss: 0.1647 - val_accuracy: 0.8860\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 715us/sample - loss: 0.1831 - accuracy: 0.8923 - val_loss: 0.1641 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 723us/sample - loss: 0.1813 - accuracy: 0.8967 - val_loss: 0.1620 - val_accuracy: 0.8772\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 719us/sample - loss: 0.1801 - accuracy: 0.8989 - val_loss: 0.1608 - val_accuracy: 0.8772\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 708us/sample - loss: 0.1784 - accuracy: 0.8923 - val_loss: 0.1603 - val_accuracy: 0.8860\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 0.1768 - accuracy: 0.8989 - val_loss: 0.1587 - val_accuracy: 0.8860\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 705us/sample - loss: 0.1752 - accuracy: 0.8989 - val_loss: 0.1575 - val_accuracy: 0.8860\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 695us/sample - loss: 0.1739 - accuracy: 0.8967 - val_loss: 0.1569 - val_accuracy: 0.8860\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 696us/sample - loss: 0.1724 - accuracy: 0.8967 - val_loss: 0.1567 - val_accuracy: 0.8860\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 694us/sample - loss: 0.1714 - accuracy: 0.8967 - val_loss: 0.1553 - val_accuracy: 0.8860\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 694us/sample - loss: 0.1702 - accuracy: 0.8945 - val_loss: 0.1546 - val_accuracy: 0.8772\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 702us/sample - loss: 0.1683 - accuracy: 0.9011 - val_loss: 0.1534 - val_accuracy: 0.8860\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 704us/sample - loss: 0.1672 - accuracy: 0.8989 - val_loss: 0.1524 - val_accuracy: 0.8860\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 704us/sample - loss: 0.1658 - accuracy: 0.8989 - val_loss: 0.1518 - val_accuracy: 0.8860\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 0.1642 - accuracy: 0.9011 - val_loss: 0.1511 - val_accuracy: 0.8772\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 730us/sample - loss: 0.1635 - accuracy: 0.8989 - val_loss: 0.1497 - val_accuracy: 0.8860\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 756us/sample - loss: 0.1621 - accuracy: 0.8989 - val_loss: 0.1490 - val_accuracy: 0.8860\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 730us/sample - loss: 0.1609 - accuracy: 0.8967 - val_loss: 0.1484 - val_accuracy: 0.8860\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 719us/sample - loss: 0.1595 - accuracy: 0.9033 - val_loss: 0.1472 - val_accuracy: 0.8860\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 739us/sample - loss: 0.1586 - accuracy: 0.8967 - val_loss: 0.1462 - val_accuracy: 0.8860\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 733us/sample - loss: 0.1575 - accuracy: 0.8989 - val_loss: 0.1456 - val_accuracy: 0.8860\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 696us/sample - loss: 0.1562 - accuracy: 0.8989 - val_loss: 0.1449 - val_accuracy: 0.8860\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 717us/sample - loss: 0.1550 - accuracy: 0.8989 - val_loss: 0.1440 - val_accuracy: 0.8860\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 755us/sample - loss: 0.1540 - accuracy: 0.8989 - val_loss: 0.1432 - val_accuracy: 0.8860\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 709us/sample - loss: 0.1527 - accuracy: 0.8989 - val_loss: 0.1439 - val_accuracy: 0.8860\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 720us/sample - loss: 0.1516 - accuracy: 0.9033 - val_loss: 0.1418 - val_accuracy: 0.8860\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 714us/sample - loss: 0.1508 - accuracy: 0.8989 - val_loss: 0.1419 - val_accuracy: 0.8772\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 747us/sample - loss: 0.1497 - accuracy: 0.8989 - val_loss: 0.1402 - val_accuracy: 0.8860\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 742us/sample - loss: 0.1492 - accuracy: 0.8967 - val_loss: 0.1398 - val_accuracy: 0.8860\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 767us/sample - loss: 0.1475 - accuracy: 0.9011 - val_loss: 0.1405 - val_accuracy: 0.8860\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 702us/sample - loss: 0.1470 - accuracy: 0.9011 - val_loss: 0.1383 - val_accuracy: 0.8860\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 717us/sample - loss: 0.1457 - accuracy: 0.8989 - val_loss: 0.1379 - val_accuracy: 0.8860\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 721us/sample - loss: 0.1448 - accuracy: 0.8989 - val_loss: 0.1371 - val_accuracy: 0.8860\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 738us/sample - loss: 0.1438 - accuracy: 0.9033 - val_loss: 0.1364 - val_accuracy: 0.8860\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 738us/sample - loss: 0.1431 - accuracy: 0.9011 - val_loss: 0.1355 - val_accuracy: 0.8860\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 813us/sample - loss: 0.1425 - accuracy: 0.8967 - val_loss: 0.1348 - val_accuracy: 0.8860\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 792us/sample - loss: 0.1414 - accuracy: 0.8967 - val_loss: 0.1342 - val_accuracy: 0.8860\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 872us/sample - loss: 0.1399 - accuracy: 0.8989 - val_loss: 0.1341 - val_accuracy: 0.8772\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 868us/sample - loss: 0.1394 - accuracy: 0.8967 - val_loss: 0.1328 - val_accuracy: 0.8860\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 797us/sample - loss: 0.1386 - accuracy: 0.9011 - val_loss: 0.1322 - val_accuracy: 0.8860\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 806us/sample - loss: 0.1376 - accuracy: 0.8989 - val_loss: 0.1325 - val_accuracy: 0.8860\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 790us/sample - loss: 0.1359 - accuracy: 0.9055 - val_loss: 0.1351 - val_accuracy: 0.8860\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 756us/sample - loss: 0.1365 - accuracy: 0.9011 - val_loss: 0.1306 - val_accuracy: 0.8860\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 792us/sample - loss: 0.1350 - accuracy: 0.9033 - val_loss: 0.1299 - val_accuracy: 0.8860\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 789us/sample - loss: 0.1357 - accuracy: 0.8945 - val_loss: 0.1289 - val_accuracy: 0.8860\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 784us/sample - loss: 0.1337 - accuracy: 0.9011 - val_loss: 0.1286 - val_accuracy: 0.8860\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 828us/sample - loss: 0.1332 - accuracy: 0.9011 - val_loss: 0.1282 - val_accuracy: 0.8860\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 794us/sample - loss: 0.1321 - accuracy: 0.9011 - val_loss: 0.1279 - val_accuracy: 0.8860\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 801us/sample - loss: 0.1311 - accuracy: 0.8989 - val_loss: 0.1307 - val_accuracy: 0.8860\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 844us/sample - loss: 0.1303 - accuracy: 0.9033 - val_loss: 0.1280 - val_accuracy: 0.8947\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 784us/sample - loss: 0.1299 - accuracy: 0.9011 - val_loss: 0.1266 - val_accuracy: 0.8860\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 840us/sample - loss: 0.1296 - accuracy: 0.8989 - val_loss: 0.1256 - val_accuracy: 0.8860\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 916us/sample - loss: 0.1284 - accuracy: 0.9033 - val_loss: 0.1251 - val_accuracy: 0.8860\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 851us/sample - loss: 0.1273 - accuracy: 0.9055 - val_loss: 0.1248 - val_accuracy: 0.8860\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 762us/sample - loss: 0.1269 - accuracy: 0.9011 - val_loss: 0.1267 - val_accuracy: 0.8860\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 740us/sample - loss: 0.1266 - accuracy: 0.9011 - val_loss: 0.1238 - val_accuracy: 0.8860\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 718us/sample - loss: 0.1260 - accuracy: 0.9011 - val_loss: 0.1235 - val_accuracy: 0.8860\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 719us/sample - loss: 0.1252 - accuracy: 0.9011 - val_loss: 0.1229 - val_accuracy: 0.8860\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 732us/sample - loss: 0.1241 - accuracy: 0.9011 - val_loss: 0.1230 - val_accuracy: 0.8860\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 734us/sample - loss: 0.1233 - accuracy: 0.9033 - val_loss: 0.1224 - val_accuracy: 0.8860\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 730us/sample - loss: 0.1237 - accuracy: 0.8989 - val_loss: 0.1218 - val_accuracy: 0.8860\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 714us/sample - loss: 0.1227 - accuracy: 0.8989 - val_loss: 0.1214 - val_accuracy: 0.8860\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 0.1223 - accuracy: 0.9033 - val_loss: 0.1225 - val_accuracy: 0.8860\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 698us/sample - loss: 0.1217 - accuracy: 0.9055 - val_loss: 0.1209 - val_accuracy: 0.8860\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 695us/sample - loss: 0.1215 - accuracy: 0.8989 - val_loss: 0.1204 - val_accuracy: 0.8860\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 714us/sample - loss: 0.1197 - accuracy: 0.9033 - val_loss: 0.1220 - val_accuracy: 0.8860\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 0.1207 - accuracy: 0.9011 - val_loss: 0.1193 - val_accuracy: 0.8860\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 717us/sample - loss: 0.1197 - accuracy: 0.9011 - val_loss: 0.1191 - val_accuracy: 0.8860\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 735us/sample - loss: 0.1184 - accuracy: 0.9055 - val_loss: 0.1191 - val_accuracy: 0.8772\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 764us/sample - loss: 0.1195 - accuracy: 0.8989 - val_loss: 0.1185 - val_accuracy: 0.8860\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 756us/sample - loss: 0.1177 - accuracy: 0.9011 - val_loss: 0.1188 - val_accuracy: 0.8947\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 796us/sample - loss: 0.1171 - accuracy: 0.9055 - val_loss: 0.1175 - val_accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b43ce10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, target,\n",
    "            batch_size=1,\n",
    "            epochs=100,\n",
    "            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FM在应对特征丰富的推荐任务时有着很不错的效果。毕竟考虑到了特征之间的组合关系。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
